{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson�McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson�McNeely     F  ...   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  ...   \n",
       "\n",
       "      Species           Investigator or Source                     pdf  \\\n",
       "0  White shark                R. Collier, GSAF    2018.06.25-Wolfe.pdf   \n",
       "1          NaN  K.McMurray, TrackingSharks.com  2018.06.18-McNeely.pdf   \n",
       "2          NaN  K.McMurray, TrackingSharks.com   2018.06.09-Denges.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"attacks.csv\", engine=\"python\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25723 entries, 0 to 25722\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Case Number             8702 non-null   object \n",
      " 1   Date                    6302 non-null   object \n",
      " 2   Year                    6300 non-null   float64\n",
      " 3   Type                    6298 non-null   object \n",
      " 4   Country                 6252 non-null   object \n",
      " 5   Area                    5847 non-null   object \n",
      " 6   Location                5762 non-null   object \n",
      " 7   Activity                5758 non-null   object \n",
      " 8   Name                    6092 non-null   object \n",
      " 9   Sex                     5737 non-null   object \n",
      " 10  Age                     3471 non-null   object \n",
      " 11  Injury                  6274 non-null   object \n",
      " 12  Fatal (Y/N)             5763 non-null   object \n",
      " 13  Time                    2948 non-null   object \n",
      " 14  Species                 3464 non-null   object \n",
      " 15  Investigator or Source  6285 non-null   object \n",
      " 16  pdf                     6302 non-null   object \n",
      " 17  href formula            6301 non-null   object \n",
      " 18  href                    6302 non-null   object \n",
      " 19  Case Number.1           6302 non-null   object \n",
      " 20  Case Number.2           6302 non-null   object \n",
      " 21  original order          6309 non-null   float64\n",
      " 22  Unnamed: 22             1 non-null      object \n",
      " 23  Unnamed: 23             2 non-null      object \n",
      "dtypes: float64(2), object(22)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I check column by column with 'df[\"column\"]' and 'df[\"column\"].value_counts()' so that I can observe if the info is useful and if there are repeated categories or mixed formats. Results:\n",
    "\n",
    "- All the columns have NaN values.\n",
    "- Case Number: Probably unusefull. \n",
    "- Date: Mixed format.\n",
    "- Year: Mixed format and wrong data.                  \n",
    "- Type: Repeated categories with different names.                   \n",
    "- Activity: Repeated categories with different names. \n",
    "- Name: Mixed data with sex. Not relevant.  I will ignore this column.  \n",
    "- Sex: the index has a space on the right. A few repeated category because of the format. Missing values. I will ignore this column.\n",
    "- Age: mixed format. Wrong data. Missing data. I will ignore this column. I will ignore this column.\n",
    "- Fatal (Y/N): mixed format. Wrong data. \n",
    "- Time: mixed format. Missing information\n",
    "- Species: the index has a space on the right. Repeated categories with different names.\n",
    "- Investigator or Source: probably unusefull. \n",
    "- pdf:  probably unusefull. \n",
    "- href formula: Only usefull to get missing data.\n",
    "- href: Only usefull to get missing data.\n",
    "- Case Number.1: Probably unusefull.\n",
    "- Case Number.2: Probably unusefull.\n",
    "- original order: Probably unusefull.\n",
    "- Unnamed: 22: Probably unusefull.\n",
    "- Unnamed: 23: Probably unusefull.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy() # I make a copy, the clean one.\n",
    "\n",
    "# I create list comprehension of the columns I don't need to drop it:\n",
    "column_names = df_clean.columns\n",
    "columns_unuseful = [column_names[i] for i in [0,8,9,10,13,15,16,17,18,19,20,21,22,23]]\n",
    "\n",
    "df_clean.drop(columns_unuseful, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I make the column names upper case.\n",
    "df_clean.columns = df_clean.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25723 entries, 0 to 25722\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   DATE         6302 non-null   object \n",
      " 1   YEAR         6300 non-null   float64\n",
      " 2   TYPE         6298 non-null   object \n",
      " 3   COUNTRY      6252 non-null   object \n",
      " 4   AREA         5847 non-null   object \n",
      " 5   LOCATION     5762 non-null   object \n",
      " 6   ACTIVITY     5758 non-null   object \n",
      " 7   INJURY       6274 non-null   object \n",
      " 8   FATAL (Y/N)  5763 non-null   object \n",
      " 9   SPECIES      3464 non-null   object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE           19421\n",
       "YEAR           19423\n",
       "TYPE           19425\n",
       "COUNTRY        19471\n",
       "AREA           19876\n",
       "LOCATION       19961\n",
       "ACTIVITY       19965\n",
       "INJURY         19449\n",
       "FATAL (Y/N)    19960\n",
       "SPECIES        22259\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I get the sume of the NaN in my dataframe:\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE              0\n",
       "YEAR              2\n",
       "TYPE              4\n",
       "COUNTRY          50\n",
       "AREA            455\n",
       "LOCATION        540\n",
       "ACTIVITY        544\n",
       "INJURY           28\n",
       "FATAL (Y/N)     539\n",
       "SPECIES        2838\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then I drop NaN values keeping only the rows with at least 2 non-NA values:\n",
    "df_clean = df_clean.dropna(thresh=2)\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2018.0\n",
       "1       2018.0\n",
       "2       2018.0\n",
       "3       2018.0\n",
       "4       2018.0\n",
       "         ...  \n",
       "6297       0.0\n",
       "6298       0.0\n",
       "6299       0.0\n",
       "6300       0.0\n",
       "6301       0.0\n",
       "Name: YEAR, Length: 6302, dtype: float64"
      ]
     },
     "execution_count": 1126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>INJURY</th>\n",
       "      <th>FATAL (Y/N)</th>\n",
       "      <th>SPECIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>Ca. 214 B.C.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ionian Sea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ascending from a dive</td>\n",
       "      <td>FATAL, shark/s bit him in two</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>Ca. 336.B.C..</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>GREECE</td>\n",
       "      <td>Piraeus</td>\n",
       "      <td>In the haven of Cantharus</td>\n",
       "      <td>Washing his pig in preparation for a religious...</td>\n",
       "      <td>FATAL, shark \"bit off all lower parts of him u...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>493 B.C.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sea Disaster</td>\n",
       "      <td>GREECE</td>\n",
       "      <td>Off Thessaly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shipwrecked Persian Fleet</td>\n",
       "      <td>Herodotus tells of sharks attacking men in the...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE  YEAR          TYPE COUNTRY          AREA  \\\n",
       "6177   Ca. 214 B.C.   0.0    Unprovoked     NaN    Ionian Sea   \n",
       "6178  Ca. 336.B.C..   0.0    Unprovoked  GREECE       Piraeus   \n",
       "6179       493 B.C.   0.0  Sea Disaster  GREECE  Off Thessaly   \n",
       "\n",
       "                       LOCATION  \\\n",
       "6177                        NaN   \n",
       "6178  In the haven of Cantharus   \n",
       "6179                        NaN   \n",
       "\n",
       "                                               ACTIVITY  \\\n",
       "6177                              Ascending from a dive   \n",
       "6178  Washing his pig in preparation for a religious...   \n",
       "6179                          Shipwrecked Persian Fleet   \n",
       "\n",
       "                                                 INJURY FATAL (Y/N) SPECIES   \n",
       "6177                      FATAL, shark/s bit him in two           Y      NaN  \n",
       "6178  FATAL, shark \"bit off all lower parts of him u...           Y      NaN  \n",
       "6179  Herodotus tells of sharks attacking men in the...           Y      NaN  "
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean[\"YEAR\"] == 0.0].head(3)\n",
    "# We can leave out these 125 cases as they are not really significant, they are too old with a lot of missing date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>INJURY</th>\n",
       "      <th>FATAL (Y/N)</th>\n",
       "      <th>SPECIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>White shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE    YEAR        TYPE COUNTRY        AREA  \\\n",
       "0  25-Jun-2018  2018.0     Boating     USA  California   \n",
       "1  18-Jun-2018  2018.0  Unprovoked     USA     Georgia   \n",
       "2  09-Jun-2018  2018.0     Invalid     USA      Hawaii   \n",
       "\n",
       "                         LOCATION  ACTIVITY  \\\n",
       "0     Oceanside, San Diego County  Paddling   \n",
       "1  St. Simon Island, Glynn County  Standing   \n",
       "2                    Habush, Oahu   Surfing   \n",
       "\n",
       "                                              INJURY FATAL (Y/N)     SPECIES   \n",
       "0  No injury to occupant, outrigger canoe and pad...           N  White shark  \n",
       "1                         Minor injury to left thigh           N          NaN  \n",
       "2       Injury to left lower leg from surfboard skeg           N          NaN  "
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After this evaluation I will keep only the relevant data which would be from 1950:\n",
    "df_clean = df_clean[df_clean[\"YEAR\"] >= 1950]\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957                            11\n",
       "1956                             8\n",
       "1950                             7\n",
       "1958                             7\n",
       "28-Jul-1995                      5\n",
       "                                ..\n",
       "30-Mar-1971                      1\n",
       "Mid Jul-1985 or mid Jul-1986     1\n",
       "12-Aug-2014                      1\n",
       "Reported      10-Dec-1994        1\n",
       "20-Mar-1967                      1\n",
       "Name: DATE, Length: 3817, dtype: int64"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"DATE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(set(df_clean[\"DATE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"DATE\"]=df_clean[\"DATE\"].str.strip(\"Reported\")\n",
    "df_clean[\"DATE\"]=df_clean[\"DATE\"].str.strip(\" Reported\")\n",
    "df_clean[\"DATE\"]=df_clean[\"DATE\"].str.strip(\".Reported\")\n",
    "df_clean[\"DATE\"]=df_clean[\"DATE\"].str.strip(\"Late 1600s Reported\")\n",
    "df_clean[\"DATE\"]=df_clean[\"DATE\"].str.strip('Reported to have happened  \"on the weekend\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(set(df_clean[\"DATE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MONTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a new columns only with months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I try to create a new column with months. But it didn't work...\n",
    "df_clean[\"MONTH\"] = np.where(df_clean[\"DATE\"].str.contains(\"Jan\"), \"Jan\", df_clean[\"DATE\"])\n",
    "def months_column(x,y):\n",
    "    df_clean[\"MONTH\"] = np.where(df_clean[\"DATE\"].str.contains(x), y, df_clean[\"MONTH\"])\n",
    "months_column(\"Jan\",\"Jan\")\n",
    "months_column(\"Feb\", \"Feb\")\n",
    "months_column(\"Mar\", \"Mar\")\n",
    "months_column(\"Apr\", \"Apr\")\n",
    "months_column(\"May\",\"May\")\n",
    "months_column(\"Jun\",\"Jun\")\n",
    "months_column(\"Jul\",\"Jul\")\n",
    "months_column(\"Aug\",\"Aug\")\n",
    "months_column(\"Sep\",\"Sep\")\n",
    "months_column(\"Oct\",\"Oct\")\n",
    "months_column(\"Nov\",\"Nov\")\n",
    "months_column(\"Dec\",\"Dec\")\n",
    "\n",
    "df_clean['MONTH']=np.where(df_clean['MONTH'].str.contains(\"Ap\"), \"Apr\", df_clean['MONTH'])\n",
    "df_clean['MONTH']=np.where(df_clean['MONTH'].str.contains(\"Summer\"), \"Summer\", df_clean['MONTH'])\n",
    "df_clean['MONTH']=np.where(df_clean['MONTH'].str.contains(\"summer\"), \"Summer\", df_clean['MONTH'])\n",
    "df_clean['MONTH']=np.where(df_clean['MONTH'].str.contains(\"Fall\"), \"Fall\", df_clean['MONTH'])\n",
    "df_clean['MONTH']=np.where(df_clean['MONTH'].str.contains(\"Winter\"), \"Winter\", df_clean['MONTH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jun' 'May' 'Apr' 'Mar' 'Feb' 'Jan' 'Dec' 'Nov' 'Oct' 'Sep' 'Aug' 'Jul'\n",
      " '2017.06.05' '2014' '2008.01.3' 'Fall' 'Summer' '2004' '2' '999' '998'\n",
      " '99' '995' 'incident of 1994 in Hong Kong' '994' '993' '992' '989' '988'\n",
      " '987' '98' '985' '984' 'Ca. 1983' '983' '982' '2-30-198' '979' '978' '97'\n",
      " '975' '974' '973' '972' 'Ca. 197' 'Winter' '968' '965' 'Early 1965'\n",
      " 'Ca. 1965' 'Early 1963' '963' '962' 'Ca. 1962' '9' '960-19' 'Ca. 19'\n",
      " '21764' '959' '958-1959' '958' 'Circa 1958' '957' '95' '955' 'Ca. 1955'\n",
      " '9955' '954' '954 (same day as  1954.00.00.f)' '953' '952-1954' '952'\n",
      " '\\n1951.12.15' '950.07.19' '950 - 195' 'Ca. 195']\n"
     ]
    }
   ],
   "source": [
    "print (df_clean['MONTH'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Boating\n",
       "1       Unprovoked\n",
       "2          Invalid\n",
       "3       Unprovoked\n",
       "4         Provoked\n",
       "           ...    \n",
       "4493    Unprovoked\n",
       "4494    Unprovoked\n",
       "4495    Unprovoked\n",
       "4496    Unprovoked\n",
       "4497    Unprovoked\n",
       "Name: TYPE, Length: 4497, dtype: object"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"TYPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boating' 'Unprovoked' 'Invalid' 'Provoked' 'Questionable' 'Sea Disaster'\n",
      " nan 'Boat' 'Boatomg']\n"
     ]
    }
   ],
   "source": [
    "print (df_clean['TYPE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['TYPE']=df_clean['TYPE'].fillna(\"Unknown\")\n",
    "\n",
    "df_clean['TYPE']=np.where(df_clean['TYPE'].str.startswith('Boa'), \n",
    "                            \"Boating\", \n",
    "                            df_clean['TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boating' 'Unprovoked' 'Invalid' 'Provoked' 'Questionable' 'Sea Disaster'\n",
      " 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print (df_clean['TYPE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                Paddling\n",
       "1                                                Standing\n",
       "2                                                 Surfing\n",
       "3                                                 Surfing\n",
       "4                                             Free diving\n",
       "                              ...                        \n",
       "4493                                             Swimming\n",
       "4494                                     Diving for coins\n",
       "4495    Spearfishing, but walking carrying fish on end...\n",
       "4496              Helmet diving, collecting trochus shell\n",
       "4497                                                  NaN\n",
       "Name: ACTIVITY, Length: 4497, dtype: object"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"ACTIVITY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['ACTIVITY'] = df_clean['ACTIVITY'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['ACTIVITY_TYPE']=df_clean['ACTIVITY'].fillna(\"Unknown\")\n",
    "df_clean['ACTIVITY_TYPE']=np.where(df_clean['ACTIVITY'].str.contains(\"surf\"), \"Surfing\", df_clean['ACTIVITY'])\n",
    "df_clean['ACTIVITY_TYPE']=np.where(df_clean['ACTIVITY'].str.contains(\"div\"), \"Diving\", df_clean['ACTIVITY_TYPE'])\n",
    "df_clean['ACTIVITY_TYPE']=np.where(df_clean['ACTIVITY'].str.contains(\"swim\"), \"Swiming\", df_clean['ACTIVITY_TYPE'])\n",
    "df_clean['ACTIVITY_TYPE']=np.where(df_clean['ACTIVITY'].str.contains(\"fish\"), \"Fishing\", df_clean['ACTIVITY_TYPE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (df_clean['ACTIVITY_TYPE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'AUSTRALIA' 'MEXICO' 'BRAZIL' 'ENGLAND' 'SOUTH AFRICA' 'THAILAND'\n",
      " 'COSTA RICA' 'MALDIVES' 'BAHAMAS' 'NEW CALEDONIA' 'ECUADOR' 'MALAYSIA'\n",
      " 'LIBYA' nan 'CUBA' 'MAURITIUS' 'NEW ZEALAND' 'SPAIN' 'SAMOA'\n",
      " 'SOLOMON ISLANDS' 'JAPAN' 'EGYPT' 'ST HELENA, British overseas territory'\n",
      " 'COMOROS' 'REUNION' 'FRENCH POLYNESIA' 'UNITED KINGDOM'\n",
      " 'UNITED ARAB EMIRATES' 'PHILIPPINES' 'INDONESIA' 'CHINA' 'COLUMBIA'\n",
      " 'CAPE VERDE' 'Fiji' 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA'\n",
      " 'MOZAMBIQUE' 'FIJI' 'PUERTO RICO' 'ITALY' 'ATLANTIC OCEAN' 'GREECE'\n",
      " 'ST. MARTIN' 'FRANCE' 'PAPUA NEW GUINEA' 'TRINIDAD & TOBAGO' 'KIRIBATI'\n",
      " 'ISRAEL' 'DIEGO GARCIA' 'TAIWAN' 'JAMAICA' 'PALESTINIAN TERRITORIES'\n",
      " 'GUAM' 'SEYCHELLES' 'BELIZE' 'NIGERIA' 'TONGA' 'SCOTLAND' 'CANADA'\n",
      " 'CROATIA' 'SAUDI ARABIA' 'CHILE' 'ANTIGUA' 'KENYA' 'RUSSIA'\n",
      " 'TURKS & CAICOS' 'UNITED ARAB EMIRATES (UAE)' 'AZORES' 'SOUTH KOREA'\n",
      " 'MALTA' 'VIETNAM' 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS'\n",
      " 'BRITISH VIRGIN ISLANDS' 'NORWAY' 'SENEGAL' 'YEMEN' 'GULF OF ADEN'\n",
      " 'Sierra Leone' 'ST. MAARTIN' 'GRAND CAYMAN' 'Seychelles' 'LIBERIA'\n",
      " 'VANUATU' 'MEXICO ' 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY'\n",
      " 'INDIA' 'MICRONESIA' 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA'\n",
      " 'MARSHALL ISLANDS' 'EGYPT / ISRAEL' 'NORTHERN ARABIAN SEA' 'HONG KONG'\n",
      " 'EL SALVADOR' 'ANGOLA' 'BERMUDA' 'MONTENEGRO' 'IRAN' 'TUNISIA' 'NAMIBIA'\n",
      " 'NORTH ATLANTIC OCEAN' 'PORTUGAL' 'SOUTH CHINA SEA' 'BANGLADESH' 'PALAU'\n",
      " 'WESTERN SAMOA' 'PACIFIC OCEAN ' 'BRITISH ISLES' 'GRENADA' 'IRAQ'\n",
      " 'TURKEY' 'SINGAPORE' 'NEW BRITAIN' 'SUDAN' 'JOHNSTON ISLAND'\n",
      " 'SOUTH PACIFIC OCEAN' 'NEW GUINEA' 'RED SEA' 'NORTH PACIFIC OCEAN'\n",
      " 'FEDERATED STATES OF MICRONESIA' 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS'\n",
      " 'BRITISH WEST INDIES' 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF'\n",
      " 'RED SEA / INDIAN OCEAN' 'PACIFIC OCEAN' 'NORTH SEA' 'NICARAGUA '\n",
      " 'MALDIVE ISLANDS' 'AMERICAN SAMOA' 'ANDAMAN / NICOBAR ISLANDAS' 'GABON'\n",
      " 'MAYOTTE' 'NORTH ATLANTIC OCEAN ' 'THE BALKANS' 'SUDAN?' 'ARGENTINA'\n",
      " 'MARTINIQUE' 'INDIAN OCEAN' 'GUATEMALA' 'NETHERLANDS ANTILLES']\n"
     ]
    }
   ],
   "source": [
    "print (df_clean['COUNTRY'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['COUNTRY'] = df_clean['COUNTRY'].str.upper() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Irealize that this methode change the NaN elements, so first of all I have to re-fill them.\n",
    "df_clean['COUNTRY']=df_clean['COUNTRY'].fillna(\"UNKNOWN\")\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"EMIRATES\"), \"UNITED ARAB EMIRATES\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"ENGLAND\"), \"UNITED KINGDOM\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"ST. MAARTIN\"), \"ST. MARTIN\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"BRITISH ISLES\"), \"UNITED KINGDOM\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"SUDAN?\"), \"SUDAN\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"NEW GUINEA\"), \"PAPUA NEW GUINEA\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"RED SEA\"), \"RED SEA\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"GRAND CAYMAN\"), \"CAYMAN ISLANDS\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"FEDERATED STATES OF MICRONESIA\"), \"MICRONESIA\", df_clean['COUNTRY'])\n",
    "df_clean['COUNTRY']=np.where(df_clean['COUNTRY'].str.contains(\"PACIFIC OCEAN \"), \"PACIFIC OCEAN\", df_clean['COUNTRY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'AUSTRALIA' 'MEXICO' 'BRAZIL' 'UNITED KINGDOM' 'SOUTH AFRICA'\n",
      " 'THAILAND' 'COSTA RICA' 'MALDIVES' 'BAHAMAS' 'NEW CALEDONIA' 'ECUADOR'\n",
      " 'MALAYSIA' 'LIBYA' 'UNKNOWN' 'CUBA' 'MAURITIUS' 'NEW ZEALAND' 'SPAIN'\n",
      " 'SAMOA' 'SOLOMON ISLANDS' 'JAPAN' 'EGYPT'\n",
      " 'ST HELENA, BRITISH OVERSEAS TERRITORY' 'COMOROS' 'REUNION'\n",
      " 'FRENCH POLYNESIA' 'UNITED ARAB EMIRATES' 'PHILIPPINES' 'INDONESIA'\n",
      " 'CHINA' 'COLUMBIA' 'CAPE VERDE' 'FIJI' 'DOMINICAN REPUBLIC'\n",
      " 'CAYMAN ISLANDS' 'ARUBA' 'MOZAMBIQUE' 'PUERTO RICO' 'ITALY'\n",
      " 'ATLANTIC OCEAN' 'GREECE' 'ST. MARTIN' 'FRANCE' 'PAPUA NEW GUINEA'\n",
      " 'TRINIDAD & TOBAGO' 'KIRIBATI' 'ISRAEL' 'DIEGO GARCIA' 'TAIWAN' 'JAMAICA'\n",
      " 'PALESTINIAN TERRITORIES' 'GUAM' 'SEYCHELLES' 'BELIZE' 'NIGERIA' 'TONGA'\n",
      " 'SCOTLAND' 'CANADA' 'CROATIA' 'SAUDI ARABIA' 'CHILE' 'ANTIGUA' 'KENYA'\n",
      " 'RUSSIA' 'TURKS & CAICOS' 'AZORES' 'SOUTH KOREA' 'MALTA' 'VIETNAM'\n",
      " 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS' 'BRITISH VIRGIN ISLANDS' 'NORWAY'\n",
      " 'SENEGAL' 'YEMEN' 'GULF OF ADEN' 'SIERRA LEONE' 'LIBERIA' 'VANUATU'\n",
      " 'MEXICO ' 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY' 'INDIA'\n",
      " 'MICRONESIA' 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA' 'MARSHALL ISLANDS'\n",
      " 'EGYPT / ISRAEL' 'NORTHERN ARABIAN SEA' 'HONG KONG' 'EL SALVADOR'\n",
      " 'ANGOLA' 'BERMUDA' 'MONTENEGRO' 'IRAN' 'TUNISIA' 'NAMIBIA'\n",
      " 'NORTH ATLANTIC OCEAN' 'PORTUGAL' 'SOUTH CHINA SEA' 'BANGLADESH' 'PALAU'\n",
      " 'WESTERN SAMOA' 'PACIFIC OCEAN' 'GRENADA' 'IRAQ' 'TURKEY' 'SINGAPORE'\n",
      " 'NEW BRITAIN' 'SUDAN' 'JOHNSTON ISLAND' 'SOUTH PACIFIC OCEAN' 'RED SEA'\n",
      " 'NORTH PACIFIC OCEAN' 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS'\n",
      " 'BRITISH WEST INDIES' 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF' 'NORTH SEA'\n",
      " 'NICARAGUA ' 'MALDIVE ISLANDS' 'AMERICAN SAMOA'\n",
      " 'ANDAMAN / NICOBAR ISLANDAS' 'GABON' 'MAYOTTE' 'NORTH ATLANTIC OCEAN '\n",
      " 'THE BALKANS' 'ARGENTINA' 'MARTINIQUE' 'INDIAN OCEAN' 'GUATEMALA'\n",
      " 'NETHERLANDS ANTILLES']\n"
     ]
    }
   ],
   "source": [
    "print (df_clean['COUNTRY'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_clean['AREA'].unique())\n",
    "#too messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INJURY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_clean['INJURY'].unique())\n",
    "#too messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FATAL (Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Y' nan 'M' 'UNKNOWN' '2017' ' N']\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['FATAL (Y/N)'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['FATAL (Y/N)']=df_clean['FATAL (Y/N)'].fillna(\"UNKNOWN\")\n",
    "df_clean['FATAL (Y/N)']=np.where(df_clean['FATAL (Y/N)'].str.contains(\"M\"), \"N\", df_clean['FATAL (Y/N)'])\n",
    "df_clean['FATAL (Y/N)']=np.where(df_clean['FATAL (Y/N)'].str.contains(\" N\"), \"N\", df_clean['FATAL (Y/N)'])\n",
    "df_clean['FATAL (Y/N)']=np.where(df_clean['FATAL (Y/N)'].str.contains(\"2017\"), \"N\", df_clean['FATAL (Y/N)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Y' 'UNKNOWN']\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['FATAL (Y/N)'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                0\n",
       "YEAR                0\n",
       "TYPE                0\n",
       "COUNTRY             0\n",
       "AREA              217\n",
       "LOCATION          272\n",
       "ACTIVITY          320\n",
       "INJURY             15\n",
       "FATAL (Y/N)         0\n",
       "SPECIES          1602\n",
       "MONTH               0\n",
       "ACTIVITY_TYPE       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['White shark' nan '2 m shark' ...\n",
      " \"Tiger shark, 3.7 m to 4.3 m  [12' to 14']\"\n",
      " 'Alleged to involve a white shark \"with little yellow eyes\"'\n",
      " \"2.7 m [9'] shark with black-tipped pectoral fins\"]\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['SPECIES '].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['SPECIES'] = df_clean['SPECIES '].fillna(\"UNKNOWN\")\n",
    "df_clean['SPECIES'] = df_clean['SPECIES'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['SPECIES']=np.where(df_clean['SPECIES'].str.contains(\"white\"), \"white shark\", df_clean['SPECIES'])\n",
    "df_clean['SPECIES']=np.where(df_clean['SPECIES'].str.contains(\"tiger\"), \"tiger shark\", df_clean['SPECIES'])\n",
    "df_clean['SPECIES']=np.where(df_clean['SPECIES'].str.contains(\"bull\"), \"bull shark\", df_clean['SPECIES'])\n",
    "df_clean['SPECIES']=np.where(df_clean['SPECIES'].str.contains(\"blacktip\"), \"blacktip shark\", df_clean['SPECIES'])\n",
    "df_clean['SPECIES']=np.where(df_clean['SPECIES'].str.contains(\"lemon\"), \"lemon shark\", df_clean['SPECIES'])\n",
    "df_clean['SPECIES']=np.where(df_clean['SPECIES'].str.contains(\"grey\"), \"grey shark\", df_clean['SPECIES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['White shark' nan '2 m shark' ...\n",
      " \"Tiger shark, 3.7 m to 4.3 m  [12' to 14']\"\n",
      " 'Alleged to involve a white shark \"with little yellow eyes\"'\n",
      " \"2.7 m [9'] shark with black-tipped pectoral fins\"]\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['SPECIES '].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                0\n",
       "YEAR                0\n",
       "TYPE                0\n",
       "COUNTRY             0\n",
       "AREA              217\n",
       "LOCATION          272\n",
       "ACTIVITY          320\n",
       "INJURY             15\n",
       "FATAL (Y/N)         0\n",
       "SPECIES          1602\n",
       "MONTH               0\n",
       "ACTIVITY_TYPE       0\n",
       "SPECIES             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['SPECIES'] = df_clean['SPECIES'].fillna(\"Unknown\")\n",
    "df_clean.isna().sum()\n",
    "#What am I doing wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>INJURY</th>\n",
       "      <th>FATAL (Y/N)</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>ACTIVITY_TYPE</th>\n",
       "      <th>SPECIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>paddling</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>White shark</td>\n",
       "      <td>Jun</td>\n",
       "      <td>paddling</td>\n",
       "      <td>white shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>standing</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jun</td>\n",
       "      <td>standing</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>2 m shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>free diving</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Diving</td>\n",
       "      <td>tiger shark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE    YEAR        TYPE    COUNTRY             AREA  \\\n",
       "0  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1   8-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2   9-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3   8-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4   4-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         LOCATION     ACTIVITY  \\\n",
       "0     Oceanside, San Diego County     paddling   \n",
       "1  St. Simon Island, Glynn County     standing   \n",
       "2                    Habush, Oahu      surfing   \n",
       "3              Arrawarra Headland      surfing   \n",
       "4                        La Ticla  free diving   \n",
       "\n",
       "                                              INJURY FATAL (Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "3                          Minor injury to lower leg           N   \n",
       "4  Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "\n",
       "          SPECIES  MONTH ACTIVITY_TYPE      SPECIES  \n",
       "0      White shark   Jun      paddling  white shark  \n",
       "1              NaN   Jun      standing      unknown  \n",
       "2              NaN   Jun       Surfing      unknown  \n",
       "3        2 m shark   Jun       Surfing    2 m shark  \n",
       "4  Tiger shark, 3m   Jun        Diving  tiger shark  "
      ]
     },
     "execution_count": 1161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_clean' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(r'pandas-project\\attacks_clean.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
